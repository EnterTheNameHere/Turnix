{
  "Mistral 7B Instruct v0.3 Q6_K": {
    "path": "W:/Tools/llama.cpp/build/bin/Release/llama-server.exe",
    "args": "--model W:\AI\LLM\models\mradermacher\Mistral-7B-Instruct-v0-3-Q6_K-GGUF\Mistral-7B-Instruct-v0.3.Q6_K.gguf --slots --metrics --props --port 1234 --ctx-size 32768 --gpu-layers 33"
  },
  "Mistral 7b uncensored Q6_K": {
    "path": "W:/Tools/llama.cpp/build/bin/Release/llama-server.exe",
    "args": "--model W:\AI\LLM\models\mradermacher\mistral-7b-uncensored-Q6_K-GGUF\mistral-7b-uncensored.Q6_K.gguf --slots --metrics --props --port 1234 --ctx-size 32768 --gpu-layers 33"
  },
  "UTENA 7B NSFW V2 i1 Q6_K": {
    "path": "W:/Tools/llama.cpp/build/bin/Release/llama-server.exe",
    "args": "--model W:\AI\LLM\models\mradermacher\UTENA-7B-NSFW-V2-i1-Q6_K-GGUF\UTENA-7B-NSFW-V2.i1-Q6_K.gguf --slots --metrics --props --port 1234 --ctx-size 32768 --gpu-layers 33"
  },
  "UTENA 7B NSFW Q6_K": {
    "path": "W:/Tools/llama.cpp/build/bin/Release/llama-server.exe",
    "args": "--model W:\AI\LLM\models\mradermacher\UTENA-7B-NSFW-V2-Q6_K-GGUF\UTENA-7B-NSFW-V2.Q6_K.gguf --slots --metrics --props --port 1234 --ctx-size 32768 --gpu-layers 33"
  },
  "dolphin 2.1 mistral 7b Q6_K": {
    "path": "W:/Tools/llama.cpp/build/bin/Release/llama-server.exe",
    "args": "--model W:\AI\LLM\models\mradermacher\dolphin-2.1-mistral-7b-q6_k.GGUF\dolphin-2.1-mistral-7b.Q6_K.gguf --slots --metrics --props --port 1234 --ctx-size 32768 --gpu-layers 33"
  },
  "dolphin 2.9.3 mistral 7B 32k Q6_K": {
    "path": "W:/Tools/llama.cpp/build/bin/Release/llama-server.exe",
    "args": "--model W:\AI\LLM\models\mradermacher\dolphin-2.9.3-mistral-7B-32k-Q6_K-GGUF\dolphin-2.9.3-mistral-7B-32k.Q6_K.gguf --slots --metrics --props --port 1234 --ctx-size 32768 --gpu-layers 33"
  },
  "dragon mistral 0.3 Q6_K": {
    "path": "W:/Tools/llama.cpp/build/bin/Release/llama-server.exe",
    "args": "--model W:\AI\LLM\models\mradermacher\dragon-mistral-0.3-Q6_K-GGUF\dragon-mistral-0.3.Q6_K.gguf --slots --metrics --props --port 1234 --ctx-size 32768 --gpu-layers 33"
  },
  "Mistral 7B v0.3 Q6_K": {
    "path": "W:/Tools/llama.cpp/build/bin/Release/llama-server.exe",
    "args": "--model W:\AI\LLM\models\mradermacher\Mistral-7B-v0.3-Q6_K-GGUF\Mistral-7B-v0.3.Q6_K.gguf --slots --metrics --props --port 1234 --ctx-size 32768 --gpu-layers 33"
  },
  "MistralLite Q6_K": {
    "path": "W:/Tools/llama.cpp/build/bin/Release/llama-server.exe",
    "args": "--model W:\AI\LLM\models\mradermacher\MistralLite-Q6_K-GGUF\MistralLite.Q6_K.gguf --slots --metrics --props --port 1234 --ctx-size 32768 --gpu-layers 33"
  },
  "mistral orpo capybara 7k Q6_K": {
    "path": "W:/Tools/llama.cpp/build/bin/Release/llama-server.exe",
    "args": "--model W:\AI\LLM\models\mradermacher\mistral-orpo-capybara-7k-Q6_K-GGUF\mistral-orpo-capybara-7k.Q6_K.gguf --slots --metrics --props --port 1234 --ctx-size 32768 --gpu-layers 33"
  },
  "OLMo 2 1124 7B Instruct Q6_K": {
    "path": "W:/Tools/llama.cpp/build/bin/Release/llama-server.exe",
    "args": "--model W:\AI\LLM\models\bartowski\OLMo-2-1124-7B-Instruct-Q6_K-GGUF\OLMo-2-1124-7B-Instruct-Q6_K.gguf --slots --metrics --props --port 1234 --gpu-layers 33"
  }
}
