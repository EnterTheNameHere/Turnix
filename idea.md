**Turnix Project Blueprint (Updated)**

---

**Project Name:** Turnix\
**Core Purpose:** Modular AI-driven narrative and simulation engine with real-time pipeline extensibility, built for both experimentation and RPG-style storytelling.

> ‚ö†Ô∏è **Disclaimer:** Variable/class/property/member names are not final and subject to change.

---

## üåç Core Philosophy

Turnix is designed to be:

- **Extensible**: Modders and developers can hook into every part of the AI pipeline.
- **Deterministic**: Hook and pipeline execution is fully predictable.
- **Composable**: Internal systems such as memory, prompts, and world state can be re-ordered and reused.
- **View-aware**: Supports UI layout as a composition of views within a single client.
- **Template-driven**: Prompt generation is modular and model-aware, with compatibility testing and fallback support.

---

## ‚öôÔ∏è Architecture Overview

### 1. **Frontend (JS/HTML or Electron)**

- Each tab, window, or device is a **view**, identified by a `viewId`, all linked to a single `clientId` (the user/game instance).
- Each view runs its own JS runtime: `rpc.js`, `modloader.js`, `frontendBus`, and hook loader.
- Mods register hooks per view programmatically (not via manifest).
- Mods may also request creation of new views via backend (`requestView`).
- The frontend runtime loads only the mods and hooks relevant to its own `viewId`.
- Frontend WebSocket authentication uses per-view signed tokens generated by backend.

### 2. **Backend (Python)**

- FastAPI + WebSocket server
- Clients (users) can have multiple views (tabs/windows/devices)
- Mods are isolated per view and run hooks deterministically:
  - Sorted by `mod_id`
  - Then by `view_id` ("main" is always first)
  - Then by registration order (view creation time)
- Shared memory is available per mod, view-agnostic but deterministic
- Backend owns all memory, logging, model API, and pipeline scheduling
- **Authentication**: Signed tokens (e.g. HMAC) issued by backend for view WebSocket connections

### 3. **Mod System**

- Mods register hooks **programmatically** via runtime lifecycle methods:
  - `init()`: general init (non-view specific)
  - `activate(viewId)`: register hooks for a view
  - `deactivate(viewId)`: optional cleanup
  - `teardown()`: full mod unload
  - `pipelineCreated(pipeline)`: optional callback when new pipeline is instantiated
- Mod manifest describes only **metadata**, not hook declarations
- Mods can request new views from backend (`requestView(...)`) and hook into them

---

## üì¶ ModLoader Behavior

### Lifecycle Phases

- **Phase 0: Boot** ‚Äî Turnix backend starts, no mods loaded
- **Phase 1: Frontend Loads** ‚Äî view connects, JS identifies view and sends `frontendReady`
- Backend then loads Python mods, resolving dependencies

### Mod Discovery

- All mods live under `mods/` (recursively)
- Valid mod folder must include `mod.py` or `mod.js`
- Optional manifest: `manifest.yaml`, `mod.yaml`, or `package.json`

### Manifest Schema

Supports either YAML or NPM-style JSON:

```yaml
modId: chat-ui
displayName: "Chat Interface"
version: "1.0.2"
dependencies:
  - ui-button
  - { modId: audio-core, version: "^1.1.0" }
before:
  - debug-logger
after:
  - theme-dark
author: Jane Doe
tags: ["ui", "chat"]
order: 10
type: ui
hidden: false
```

### Loading

- JS mods are loaded using `import()` after main view is ready
- Python mods are activated via `Turnix.import("mod-id")`

### Ordering and Dependencies

- Explicit via `dependencies`
- Implicit via `Turnix.import()` usage
- Ordered by `order`, `before`, `after`
- Circular imports raise errors

### Access API

```python
Turnix.import("chat-ui")
Turnix.mods["chat-ui"]
```

```js
const mod = await Turnix.import("chat-ui")
```

---

## ‚öñÔ∏è Pipeline Model

The pipeline consists of deterministic, hookable stages:

- `ValidateInput`: basic checks
- `SanitizeInput`: clean input (case, profanity, etc.)
- `GenerateQueryItems`: extract reasoning units
- `FilterQueryItems`: prune and structure input
- `FinalizePrompt`: build prompt for LLM
- `__MODEL_CALL__`: LLM receives prompt
- `SanitizeResponse`: clean model output (per chunk)
- `ValidateResponse`: confirm chunk correctness
- `ProcessResponseAndUpdateState`: apply chunk effects (per chunk)
- `FinalizeResponse`: post-processing after full reply

Each stage is executed in order. `SanitizeResponse`, `ValidateResponse`, and `ProcessResponseAndUpdateState` are called per stream chunk. Others run once.

### Streaming Guarantees

- `soFar` is always the accumulated, sanitized, validated output.
- `chunk` is the current sanitized, validated piece.
- `isFinal` is true only for the last response segment.

### Memory Behavior

- All mod memory is transactionally buffered per pipeline.
- Changes are committed in `FinalizeResponse`, or discarded on `abort` / `retry`.

### Abort / Retry / Continue Logic

- Mods may request `abort`, `retry`, or `continue` in `ValidateResponse`
- `abort` and `retry` only work if transactional memory is in use
- `continue` launches a follow-up pipeline with current `soFar`

---

## üß† Pipeline Roles

- **Session**: Owns running pipelines and active mods
- **Game**: World state holder, persistent memory, and active session
- **Pipeline**: A full request-response cycle
- **Driver**: Backend model processor (LLM, TTS, etc.)
- **View**: A user interface with WebSocket connection and mod scope

### Session Variants

- `MainSession`: Core gameplay
- `TemporarySession`: One-shot subreasoning
- `HiddenSession`: Isolated, invisible unless debug mode

---

## üß© Mod Behavior by Stage

| Stage                | Mod Role                         |
| -------------------- | -------------------------------- |
| `ValidateInput`      | Reject unsafe/invalid input      |
| `SanitizeInput`      | Normalize input text             |
| `GenerateQueryItems` | Add reasoning units / meta info  |
| `FilterQueryItems`   | Prune and organize inputs        |
| `FinalizePrompt`     | Convert to prompt text           |
| `SanitizeResponse`   | Clean model chunk                |
| `ValidateResponse`   | Check validity, optionally alter |
| `ProcessResponse...` | Apply state/UI effect per chunk  |
| `FinalizeResponse`   | Commit memory, finalize pipeline |

---

## üßæ Command System via QueryItems

Mods may register commands (e.g. `/weather.set rain`) using:

```python
self.registerCommand("weather.set", self.cmdSetWeather)
```

When `ValidateInput` sees a command string, it transforms it into a `QueryItem`:

```python
pipeline.addQueryItem({
  type: "command",
  command: "weather.set",
  args: ["rain"],
  metadata: { source: "chat" }
})
```

If command handler returns a result, it can:

- Cancel pipeline (early response)
- Modify memory
- Launch subpipeline

---

## üßë‚Äçüíª UI Template Injection

Mods can provide UI fragments via:

```python
self.registerTemplate("myPanel", {
  html: "/mods/my/ui/panel.html",
  js: "/mods/my/ui/panel.js",
  css: "/mods/my/ui/panel.css"
})
```

Frontend runtime loads it and calls:

```js
window.TurnixUI = {
  render(props), destroy(), onMessage(msg)
}
```

---

## ‚úÖ Summary

Turnix is a deterministic, composable, UI-aware pipeline framework with:

- Modular, hookable pipeline stages
- View-isolated JS mods with dynamic template injection
- Shared transactional memory per mod, per pipeline
- Mod discovery and activation with ordering and dependencies
- Support for LLM streaming and chunk-wise processing
- Commands, prompts, and subpipelines
- Robust fallback and retry handling without leaving dirty state

