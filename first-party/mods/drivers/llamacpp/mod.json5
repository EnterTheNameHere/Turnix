// first-party/mods/drivers/llamacpp/mod.json5
{
    id: "llama.cpp",
    name: "llama.cpp Driver",
    author: "Turnix",
    version: "0.2.0",
    description: "Connects to a local llama.cpp server.",
    hidden: true,
    tags: ["driver"],
    runtimes: {
        python: {
            entry: "llamacpp_client.py",
            enabled: true,
            order: -1000,
            permissions: [],
            capabilities: ["chat@1"],
        },
    },
}
