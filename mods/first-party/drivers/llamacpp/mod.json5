{
  id: "llama.cpp",
  name: "llama.cpp Driver",
  version: "0.2.0",
  description: "Connects to a local llama.cpp server.",
  author: "Turnix",
  tags: ["driver"],
  hidden: true,
  
  runtimes: {
    python: {
      entry: "llamacpp_client.py",
      enabled: true,
      order: -1000,
      permissions: [],
      capabilities: ["chat@1"],
    },
  },
}
